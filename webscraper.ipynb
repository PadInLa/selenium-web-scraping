{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Define lists to store job data\n",
    "job_names = []\n",
    "job_descriptions = []\n",
    "academic_levels = []\n",
    "locations = []\n",
    "salaries = []\n",
    "areas = []\n",
    "publish_dates = []\n",
    "expiring_dates = []\n",
    "ambits = []\n",
    "company_sectors = []\n",
    "contract_types = []\n",
    "open_positions = []\n",
    "job_ids = []\n",
    "professional_titles = []\n",
    "experience_levels = []\n",
    "companies = []\n",
    "visited_links = []\n",
    "\n",
    "\n",
    "try:\n",
    "    # Navigate to the webpage\n",
    "    driver.get('https://www.elempleo.com/co/ofertas-empleo/')\n",
    "\n",
    "    # Optionally, wait for some time to let the page load completely\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Close the cookie banner\n",
    "    try:\n",
    "        cookie_banner = driver.find_element(By.XPATH, '/html/body/div[10]/div/div[2]/a')\n",
    "        cookie_banner.click()\n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        pass\n",
    "\n",
    "    for i in range(1, 540):\n",
    "        for j in range(1, 51):\n",
    "            specialcase = False\n",
    "            # Find elements containing job data\n",
    "            job = driver.find_element(By.XPATH, f'/html/body/div[8]/div[3]/div[1]/div[3]/div[{j}]/div[1]/ul/li[1]/h2/a')\n",
    "            job_url = job.get_attribute('href')\n",
    "            if job_url in visited_links or job_url == 'https://www.elempleo.com/co/Error/Unexpected':\n",
    "                print(f'Skipping visited job: {job_url}')\n",
    "                j += 1\n",
    "            else:    \n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "                job.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                time.sleep(3)\n",
    "                \n",
    "                # Extract job data\n",
    "                job_name = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/h1/span') \n",
    "                job_names.append(job_name.text)\n",
    "                \n",
    "                job_description = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[1]/div/p[1]/span')\n",
    "                job_descriptions.append(job_description.text)\n",
    "                \n",
    "                salary = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[1]/p[1]/span/span[1]')\n",
    "                salaries.append(salary.text)\n",
    "                \n",
    "                area = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[2]/p[1]/span')\n",
    "                areas.append(area.text)\n",
    "                \n",
    "                ambit = driver.find_element(By.XPATH,f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[1]/p[1]/span')\n",
    "                ambits.append(ambit.text)\n",
    "                                                                                                                                        \n",
    "                publish_date = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[1]/p[3]/span[1]')\n",
    "                publish_dates.append(publish_date.text)\n",
    "                \n",
    "                expiring_date = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[2]/p[3]/span[1]')\n",
    "                expiring_dates.append(expiring_date.text)\n",
    "\n",
    "                try:\n",
    "                    company_sector = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[1]/p[4]/span')\n",
    "                \n",
    "                except NoSuchElementException:\n",
    "                    specialcase = True\n",
    "                    print('Special case')\n",
    "                    company_sector = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[1]/p[3]/span')                                                 \n",
    "                \n",
    "                company_sectors.append(company_sector.text)\n",
    "                \n",
    "                if specialcase:\n",
    "                    academic_level = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[1]/p[2]')\n",
    "                else:\n",
    "                    academic_level = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[1]/p[3]/span')\n",
    "                \n",
    "                academic_levels.append(academic_level.text)\n",
    "                \n",
    "                contract_type = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[2]/p[2]/span')\n",
    "                contract_types.append(contract_type.text)\n",
    "                \n",
    "                open_position = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[2]/p[4]')\n",
    "                open_positions.append(open_position.text)\n",
    "                \n",
    "                job_id = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[2]/p[3]/span')\n",
    "                job_ids.append(job_id.text)\n",
    "                \n",
    "                location = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[1]/p[2]/span/span/span[2]')\n",
    "                locations.append(location.text)\n",
    "                \n",
    "                experience_level = driver.find_element(By.XPATH, f'/html/body/div[7]/div[2]/div[1]/div[2]/div[2]/div[2]/p[1]/span')\n",
    "                experience_levels.append(experience_level.text)\n",
    "                                                                            \n",
    "                try:\n",
    "                    company = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[2]/div[1]/div[2]/div[1]/h2')\n",
    "                except NoSuchElementException:\n",
    "                    company = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[2]/div/div[2]/p/span/span/strong')\n",
    "                \n",
    "                companies.append(company.text)\n",
    "                \n",
    "                professional_title = driver.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[2]/p[2]')\n",
    "                try:\n",
    "                    more_prof_titles = professional_title.find_element(By.XPATH, f'/html/body/div[7]/div[1]/div/div[1]/div[2]/div[2]/p[2]/a')\n",
    "                    more_prof_titles.click()\n",
    "                    time.sleep(2)\n",
    "                    professional_titles_list = driver.find_element(By.XPATH, f'/html/body/div[1]/div[3]/div/div/div[2]/div/ul')\n",
    "                    titles = professional_titles_list.find_elements(By.TAG_NAME, 'li')\n",
    "                    for title in titles:\n",
    "                        professional_titles.append(title.text)\n",
    "                except NoSuchElementException:\n",
    "                    professional_titles.append(professional_title.text)\n",
    "                    \n",
    "                \n",
    "                visited_links.append(job_url)\n",
    "\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                time.sleep(2)\n",
    "        time.sleep(3)\n",
    "        print(f'Page {i} done')\n",
    "        print(f'Total jobs so far: {len(job_names)}')\n",
    "        next_page = driver.find_element(By.XPATH, f'/html/body/div[8]/div[3]/div[1]/div[4]/div/nav/ul/li[8]/a')\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", next_page)\n",
    "        next_page.click()\n",
    "        time.sleep(5)\n",
    "               \n",
    "finally:\n",
    "    driver.quit()\n",
    "    print('Finished scraping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(job_names, job_descriptions, academic_levels, locations, experience_levels, professional_titles, salaries, companies, ambits, areas, company_sectors, publish_dates, expiring_dates, contract_types, job_ids), columns=['Job Name','Job Description','Academic Level', 'Location', 'Experience Level', 'Professional Titles', 'Salaries', 'Companies', 'Ambits', 'Areas', 'Company Sectors', 'Publish Dates', 'Expiring Dates', 'Contract Types', 'Job IDs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('jobs.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
